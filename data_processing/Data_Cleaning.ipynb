{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshakoneru98/city_watch/blob/main/data_processing/Data_Cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1m0fzxDc54s",
        "outputId": "7610713e-8bfd-4d28-fbc5-21b6e86c4a07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting uszipcode\n",
            "  Downloading uszipcode-1.0.1-py2.py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from uszipcode) (22.2.0)\n",
            "Collecting haversine>=2.5.0\n",
            "  Downloading haversine-2.8.0-py2.py3-none-any.whl (7.7 kB)\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting pathlib-mate\n",
            "  Downloading pathlib_mate-1.2.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.5/121.5 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlalchemy-mate>=1.4.28.3\n",
            "  Downloading sqlalchemy_mate-1.4.28.4-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from uszipcode) (2.27.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from uszipcode) (1.4.47)\n",
            "Collecting atomicwrites\n",
            "  Downloading atomicwrites-1.4.1.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy>=1.4.0->uszipcode) (2.0.2)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.9/dist-packages (from sqlalchemy-mate>=1.4.28.3->uszipcode) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from pathlib-mate->uszipcode) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->uszipcode) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->uszipcode) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->uszipcode) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->uszipcode) (1.26.15)\n",
            "Building wheels for collected packages: atomicwrites\n",
            "  Building wheel for atomicwrites (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for atomicwrites: filename=atomicwrites-1.4.1-py2.py3-none-any.whl size=6955 sha256=cbc6ed865b28130c99a09a9b13ddc24cd322ec46be25780ef17f5680bf0d37df\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/b5/06/d2f34584f352e4af7d1d7ac1baf38b5d24142c8044cd024fd5\n",
            "Successfully built atomicwrites\n",
            "Installing collected packages: fuzzywuzzy, haversine, atomicwrites, sqlalchemy-mate, pathlib-mate, uszipcode\n",
            "Successfully installed atomicwrites-1.4.1 fuzzywuzzy-0.18.0 haversine-2.8.0 pathlib-mate-1.2.1 sqlalchemy-mate-1.4.28.4 uszipcode-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install uszipcode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aah-ihiwMjjs"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import pandas as pd\n",
        "import json\n",
        "import tqdm\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error\n",
        "ROOT_PATH = \"/content/drive/MyDrive/DSCI 560/Datasets/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vj-naUF5OxcF"
      },
      "outputs": [],
      "source": [
        "# common util to get necessary columns\n",
        "def get_filtered_columns(data, key_names):\n",
        "  filtered_data = []\n",
        "  for record in data:\n",
        "    row = {}\n",
        "    for key in key_names:\n",
        "      r = record\n",
        "      for key_comp in key.split('.')[:-1]:\n",
        "        r = r.get(key_comp, {})\n",
        "      row[key] = r.get(key.split('.')[-1], None)\n",
        "    filtered_data.append(row)\n",
        "  return filtered_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DxulpccOncU"
      },
      "outputs": [],
      "source": [
        "# loading business data\n",
        "business_json = json.load(open(f\"{ROOT_PATH}/business.json\"))\n",
        "print(len(business_json))\n",
        "key_names = ['business_name', 'street_address', 'city', 'zip_code', \n",
        "             'location_start_date', 'location_end_date', 'location_description']\n",
        "business_df = pd.DataFrame(get_filtered_columns(business_json, key_names))\n",
        "business_df.loc[business_df.location_end_date.isna(), 'location_end_date'] = pd.to_datetime('12-31-2023') # setting end date of currently running businesses to year end.\n",
        "business_df.location_end_date = pd.to_datetime(business_df.location_end_date, errors='coerce')\n",
        "business_df = business_df.dropna() # dropping null values\n",
        "business_df.location_start_date = pd.to_datetime(business_df.location_start_date, errors='coerce') # changing dates from string to datetime format. \n",
        "business_df.city = business_df.city.str.lower() # making everything lowercase\n",
        "del business_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slKTgTG7QvHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "749a9d7a-e725-40c7-e774-222d3e2cefa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25013\n"
          ]
        }
      ],
      "source": [
        "# loading housing data\n",
        "housing_json = json.load(open(f\"{ROOT_PATH}/housing.json\"))\n",
        "print(len(housing_json))\n",
        "key_names = ['issue_date', 'street_name', 'work_description', 'zip_code', 'valuation',\n",
        "             'of_residential_dwelling_units', \n",
        "             'floor_area_l_a_zoning_code_definition', \n",
        "             'of_stories', 'census_tract', 'floor_area_l_a_building_code_definition',\n",
        "             ]\n",
        "housing_df = pd.DataFrame(get_filtered_columns(housing_json, key_names)).dropna()\n",
        "housing_df.issue_date = pd.to_datetime(housing_df.issue_date, errors='coerce') # changing dates from string to datetime format.\n",
        "del housing_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vD1V7VuYaMNd"
      },
      "outputs": [],
      "source": [
        "# aligning dates. We do not want businesses that closed before the earliest record of houses.\n",
        "business_df_date = business_df[business_df.location_end_date >= housing_df.issue_date.min()] "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving business dataset\n",
        "business_df.to_csv(f\"{ROOT_PATH}/Cleaned_data/businesses.csv\")\n",
        "business_df_date.to_csv(f\"{ROOT_PATH}/Cleaned_data/businesses_date_aligned.csv\")"
      ],
      "metadata": {
        "id": "Ri-1rKmXb6BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We do not have city in housing data. So we use the zip code and city in businesses data to fill that column\n",
        "zip_city = {k:v for k, v in business_df[['zip_code', 'city']].values.tolist()}\n",
        "zc2 = {}\n",
        "for key in zip_city:\n",
        "  zc2[key.split(\"-\")[0]] = zip_city[key]\n",
        "housing_df['city'] = housing_df.apply(lambda x: zc2.get(x.zip_code), axis=1)\n",
        "print(housing_df.isna().sum())\n",
        "# there are no null values in city"
      ],
      "metadata": {
        "id": "xUuIQHh8dmSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving housing dataset\n",
        "housing_df.to_csv(f\"{ROOT_PATH}/Cleaned_data/housing.csv\")"
      ],
      "metadata": {
        "id": "ImAcFuOHetCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q1jfiCPcGID",
        "outputId": "21809fb9-82b2-4796-c4e1-5f5f33600a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2119797\n"
          ]
        }
      ],
      "source": [
        "# loading crime data ( part 1)\n",
        "crime1_json = json.load(open(f\"{ROOT_PATH}/crime10_19.json\"))\n",
        "print(len(crime1_json))\n",
        "key_names = list(crime1_json[0].keys())\n",
        "key_names = ['dr_no', 'date_rptd', 'date_occ', 'area', 'area_name', 'rpt_dist_no',\n",
        "            'crm_cd', 'crm_cd_desc', 'vict_age', 'vict_sex', 'vict_descent', 'vict_descent', 'location', 'lat', 'lon']\n",
        "crime_df = pd.DataFrame(crime1_json, columns=key_names)\n",
        "crime_df.date_rptd = pd.to_datetime(crime_df.date_rptd, errors='coerce') # changing dates from string to datetime format. \n",
        "crime_df.date_occ = pd.to_datetime(crime_df.date_occ, errors='coerce') # changing dates from string to datetime format. \n",
        "crime_df = crime_df.dropna() # dropping null values\n",
        "del crime1_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzONi9dzokb3",
        "outputId": "e6378d36-4a26-4fa6-dcdb-f1dab7e00ca3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "638245\n"
          ]
        }
      ],
      "source": [
        "# loading crime data ( part 2)\n",
        "crime2_json = json.load(open(f\"{ROOT_PATH}/crime20_23.json\"))\n",
        "print(len(crime2_json))\n",
        "key_names = ['dr_no', 'date_rptd', 'date_occ', 'area', 'area_name', 'rpt_dist_no',\n",
        "            'crm_cd', 'crm_cd_desc', 'vict_age', 'vict_sex', 'vict_descent', 'vict_descent', 'location', 'lat', 'lon']\n",
        "crime2_df = pd.DataFrame(crime2_json, columns=key_names)\n",
        "crime2_df.date_rptd = pd.to_datetime(crime_df.date_rptd, errors='coerce') # changing dates from string to datetime format. \n",
        "crime2_df.date_occ = pd.to_datetime(crime_df.date_occ, errors='coerce') # changing dates from string to datetime format. \n",
        "crime2_df = crime2_df.dropna() # dropping null values\n",
        "crime_df = pd.concat([crime_df, crime2_df]) # appending both crime data\n",
        "del crime2_df\n",
        "del crime2_json"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sbKmXivbzCcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9JRUXMjrYHv"
      },
      "outputs": [],
      "source": [
        "_# we do not have zipcode data in crime dataset. So, we are using uszipcode to fill in the information\n",
        "from uszipcode import SearchEngine\n",
        "sr = SearchEngine()\n",
        "\n",
        "def get_zipcode(lat, long):\n",
        "  record = sr.by_coordinates(float(lat), float(long), returns=1, radius=5)\n",
        "  if len(record) > 0:\n",
        "    return record[0].zipcode\n",
        "  else:\n",
        "    return None\n",
        "crime_df['zip_code'] = crime_df.apply(lambda x: get_zipcode(float(x.lat), float(x.lon)), axis=1)\n",
        "crime_df = crime_df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hmkx7d_br2Jy"
      },
      "outputs": [],
      "source": [
        "# aligning dates. We do not want crimes that closed before the earliest record of houses.\n",
        "crime_df_date = crime_df[crime_df.date_occ >= housing_df.issue_date.min()]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(crime_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E2AbXfNhsXC",
        "outputId": "9fe13121-77f2-4b22-9bf4-7dda0539572c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1922982"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving crime dataset\n",
        "crime_df.to_csv(f\"{ROOT_PATH}/Cleaned_data/crime.csv\")\n",
        "crime_df_date.to_csv(f\"{ROOT_PATH}/Cleaned_data/crime_date_aligned.csv\")"
      ],
      "metadata": {
        "id": "iVvv7RFkhD9e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}